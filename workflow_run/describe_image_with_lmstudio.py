import requests
import base64
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
LMSTUDIO_API = "http://localhost:1234/v1/chat/completions"
model_key = "qwen2-vl-2b-instruct"
image_path = os.path.abspath("gen/input.jpeg")

user_prompt = "Describe this image in detail."
system_prompt = (
    "This is a chat between a user and an assistant. "
    "The assistant is an expert in describing images, with detail and accuracy."
)

# –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
with open(image_path, "rb") as img_file:
    image_bytes = img_file.read()
    image_base64 = base64.b64encode(image_bytes).decode("utf-8")
    image_data_url = f"data:image/jpeg;base64,{image_base64}"

# –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
payload = {
    "model": model_key,
    "messages": [
        {
            "role": "system",
            "content": system_prompt
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_data_url
                    }
                },
                {
                    "type": "text",
                    "text": user_prompt
                }
            ]
        }
    ],
    "temperature": 0.7,
    "max_tokens": 512,
    "stream": False
}

# –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
response = requests.post(LMSTUDIO_API, json=payload)

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
if response.status_code == 200:
    data = response.json()
    reply = data["choices"][0]["message"]["content"]
    print("üì∏ –û–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:\n")
    print(reply)
else:
    print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç LM Studio: {response.status_code}\n{response.text}")
